{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# USAGE\n# python train.py\n\n# set the matplotlib backend so figures can be saved in the background\nimport matplotlib\nmatplotlib.use(\"Agg\")\n\n# import the necessary packages\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPool2D, Dense\nfrom keras.layers import Flatten, Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.callbacks import EarlyStopping\n\nimport keras.backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def csv_image_generator(inputPath, bs, lb, mode=\"train\", aug=None):\n    # open the CSV file for reading\n    f = open(inputPath, \"r\")\n\n    # loop indefinitely\n    while True:\n        # initialize our batches of images and labels\n        images = []\n        labels = []\n\n        # keep looping until we reach our batch size\n        while len(images) < bs:\n            # attempt to read the next line of the CSV file\n            line = f.readline()\n\n            # check to see if the line is empty, indicating we have\n            # reached the end of the file\n            if line == \"\":\n                # reset the file pointer to the beginning of the file\n                # and re-read the line\n                f.seek(0)\n                line = f.readline()\n\n                # if we are evaluating we should now break from our\n                # loop to ensure we don't continue to fill up the\n                # batch from samples at the beginning of the file\n                if mode == \"eval\":\n                    break\n\n            # extract the label and construct the image\n            line = line.strip().split(\",\")\n            label = line[0]\n            image = np.array([int(x) for x in line[1:]], dtype=\"uint8\")\n            image = scaler.fit_transform(image)\n            image = image.reshape((1,64, 64, 3))\n\n\t\t\t# update our corresponding batches lists\n            images.append(image)\n            labels.append(label)\n\n        ## one-hot encode the labels\n        labels = lb.transform(np.array(labels))\n\n        # if the data augmentation object is not None, apply it\n        if aug is not None:\n            (images, labels) = next(aug.flow(np.array(images),\n                labels, batch_size=bs))\n\n        # yield the batch to the calling function\n        yield (np.array(images), labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# initialize the paths to our training and testing CSV files\nTRAIN_CSV = \"../input/flowerdataset/flowerDataset/flowers17_training.csv\"\nTEST_CSV = \"../input/flowerdataset/flowerDataset/flowers17_testing.csv\"\n\n# initialize the number of epochs to train for and batch size\nNUM_EPOCHS = 75\nBS = 32\n\n# initialize the total number of training and testing image\nNUM_TRAIN_IMAGES = 0\nNUM_TEST_IMAGES = 0\n\n# open the training CSV file, then initialize the unique set of class\n# labels in the dataset along with the testing labels\nf = open(TRAIN_CSV, \"r\")\nlabels = set()\ntestLabels = []\n\n# loop over all rows of the CSV file\nfor line in f:\n\t# extract the class label, update the labels list, and increment\n\t# the total number of training images\n\tlabel = line.strip().split(\",\")[0]\n\tlabels.add(label)\n\tNUM_TRAIN_IMAGES += 1\n\n# close the training CSV file and open the testing CSV file\nf.close()\nf = open(TEST_CSV, \"r\")\n\n# loop over the lines in the testing file\nfor line in f:\n\t# extract the class label, update the test labels list, and\n\t# increment the total number of testing images\n\tlabel = line.strip().split(\",\")[0]\n\ttestLabels.append(label)\n\tNUM_TEST_IMAGES += 1\n\n# close the testing CSV file\nf.close()\n\n# create the label binarizer for one-hot encoding labels, then encode\n# the testing labels\nlb = LabelBinarizer()\nlb.fit(list(labels))\ntestLabels = lb.transform(testLabels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# construct the training image generator for data augmentation\naug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n\thorizontal_flip=True, fill_mode=\"nearest\")\n\n# initialize both the training and testing image generators\ntrainGen = csv_image_generator(TRAIN_CSV, BS, lb,\n\tmode=\"train\", aug=aug)\ntestGen = csv_image_generator(TEST_CSV, BS, lb,\n\tmode=\"train\", aug=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def modelCNN(inputShape, classes):    \n    inputX = Input(inputShape)\n\n    l1 = Conv2D(32, (3, 3), padding=\"same\", activation='relu')(inputX)\n    l1 = BatchNormalization(axis=-1)(l1)\n    l1 = Conv2D(32, (3, 3), padding=\"same\", activation='relu')(l1)\n    l1 = BatchNormalization(axis=-1)(l1)\n    l1 = MaxPool2D(pool_size=(2, 2))(l1)\n    l1 = Dropout(0.25)(l1)\n\n    # second CONV => RELU => CONV => RELU => POOL layer set\n    l2 = Conv2D(64, (3, 3), padding=\"same\", activation='relu')(l1)\n    l2 = BatchNormalization(axis=-1)(l2)\n    l2 = Conv2D(64, (3, 3), padding=\"same\", activation='relu')(l2)\n    l2 = BatchNormalization(axis=-1)(l2)\n    l2 = MaxPool2D(pool_size=(2, 2))(l2)\n    l2 = Dropout(0.25)(l2)\n\n    # third CONV => RELU => CONV => RELU => POOL layer set\n    l3 = Conv2D(128, (3, 3), padding=\"same\", activation='relu')(l2)\n    l3 = BatchNormalization(axis=-1)(l3)\n    l3 = Conv2D(128, (3, 3), padding=\"same\", activation='relu')(l3)\n    l3 = BatchNormalization(axis=-1)(l3)\n    l3 = MaxPool2D(pool_size=(2, 2))(l3)\n    l3 = Dropout(0.25)(l3)\n\n    # first (and only) set of FC => RELU layers\n    l4 = Flatten()(l3)\n    l4 = Dense(512, activation=\"relu\")(l4)\n    l4 = Dropout(0.5)(l4)\n\n    # softmax classifier\n    predictions = Dense(classes, activation=\"softmax\")(l4)\n    \n    modelCNN = Model(inputs=inputX, outputs=predictions)\n    \n    return modelCNN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K.clear_session()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = modelCNN((64,64,3), 17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train the network\nprint(\"[INFO] training w/ generator...\")\nH = model.fit_generator(\n\ttrainGen,\n\tsteps_per_epoch=NUM_TRAIN_IMAGES // BS,\n\tvalidation_data=testGen,\n\tvalidation_steps=NUM_TEST_IMAGES // BS,\n\tepochs=NUM_EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}